# -*- coding: utf-8 -*-
"""latest_heart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jEgnaP8_uJW8YAOGmUp4bvWMIYWZOC-4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("heart_disease_health_indicators_BRFSS2015.csv")

# Basic structure
print("Shape:", df.shape)
df.head()

df.info()
df.describe()

# Count nulls
print("Null values:\n", df.isnull().sum())

# Visualize if needed
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')

df.duplicated().sum()
df.drop_duplicates(inplace=True)

sns.countplot(x='HeartDiseaseorAttack', data=df)
plt.title("Heart Disease Distribution")
plt.show()

df.select_dtypes(include=['object']).columns

print(df.columns)

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Feature selection
X = df[["BMI", "Smoker", "Age", "Diabetes", "PhysActivity"]]
y = df["HeartDiseaseorAttack"]

# Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

df = pd.get_dummies(df, drop_first=True)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
import joblib

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
y_pred_lr = log_reg.predict(X_test)

print("Logistic Regression:")
print(classification_report(y_test, y_pred_lr))
print("Accuracy:", accuracy_score(y_test, y_pred_lr))

joblib.dump(log_reg, "model_logistic.pkl")

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("Random Forest:")
print(classification_report(y_test, y_pred_rf))
print("Accuracy:", accuracy_score(y_test, y_pred_rf))

joblib.dump(rf, "model_randomforest.pkl")

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

print("Decision Tree:")
print(classification_report(y_test, y_pred_dt))
print("Accuracy:", accuracy_score(y_test, y_pred_dt))

joblib.dump(dt, "model_decisiontree.pkl")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score

# Step 1: Load dataset
df = pd.read_csv("heart_disease_health_indicators_BRFSS2015.csv")

# Step 2: Take a small sample
df_small = df.sample(1000, random_state=42)

# Step 3: Prepare features and target
X = df_small[["BMI", "Smoker", "Age", "Diabetes", "PhysActivity"]]
y = df_small["HeartDiseaseorAttack"]

# Step 4: Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 5: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Step 6: Train SVM with linear kernel
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)

# Step 7: Evaluate
print("SVM (linear) results on sample:")
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train, y_train)

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)

import joblib  # Add this if you haven't already

# Save all models
joblib.dump(log_reg, "model_logistic.pkl")
joblib.dump(rf, "model_randomforest.pkl")
joblib.dump(dt, "model_decisiontree.pkl")
joblib.dump(svm, "model_svm.pkl")

# Save feature column names
joblib.dump(X.columns.tolist(), "columns.pkl")

from google.colab import files

files.download("model_logistic.pkl")
files.download("model_randomforest.pkl")
files.download("model_decisiontree.pkl")
files.download("model_svm.pkl")
files.download("columns.pkl")